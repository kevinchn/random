{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Embedding, TimeDistributed, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 25754\n"
     ]
    }
   ],
   "source": [
    "path = 'sample.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 60\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n \"$%&\\'(),-./012345689:;=?\\\\`abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 29, 31, 36, 37, 42, 33, 2, 40, 33]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning is the subfield of computer science that, according t'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 25715\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25713, 40), (25713, 40))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, input_shape=(None, 24), dropout=0.2, recurrent_dropout=0.2, implementation=2)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "#         Dropout(0.2),\n",
    "#         LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "#              consume_less='gpu'),\n",
    "#         Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "\n",
    "# model=Sequential([\n",
    "#         Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "#         LSTM(512, input_dim=n_fac),\n",
    "#         Dense(vocab_size),\n",
    "#         Activation('softmax')\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25713/25713 [==============================] - 149s - loss: 2.6575   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e3acc1978>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"machine learning is the subfield of comp\"\n",
    "    for i in range(320):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of compule th u tofsiennens ariba.. co-thurd te predetorctras san um milg thic mithe rolsong and on  athe tiles ramgencpabtemes on wfis ard ing9ses on luannangeo cofteule se= wornpast e detwat, atds an=e thiinal feifhed bas fims.\n",
      "metions actibe stax onalesidedionm repretion muplamenk ===\n",
      "\n",
      "\n",
      "lp tat art wopareticar sady doytwat \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25713/25713 [==============================] - 149s - loss: 1.9132   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e39f91cc0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of compreance sobatign to cangitation, the tore pindidens in compation inalyly and the sestaciens in to outhins in this, the recessonvisided learning algorithms ===\n",
      "\n",
      "1== learners frog bearning) algorithm hag expertien; to sene as synct the kenttuon hichinl of a pregnem learning machine learning desions )ucfieed byarned learni\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25713/25713 [==============================] - 149s - loss: 1.4017   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e39f91dd8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of computational \"tolled with hopocters. in thise hode disciplanity reural networks (aven ac and porformance algorithms come to chass of data approach course (por fo fat bialica problima rosed machine learning, alyo reprosent the targs the problem rule bwowish to statistics, wo alasyt as araproded,des. and their prediction an\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25713/25713 [==============================] - 149s - loss: 1.0687   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e39f91cf8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of computer science and best in terms of falterns where the verouo ser, to the oresevar e.\n",
      "\n",
      "\n",
      "== source es awteural networks to learned in tamged the time. that e0thidimination: in 2019, come from the qunstatis is to fpervise trenden discevering hintering, goce so1vine of paturt is respect to ox molel that various and deep lea\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25713/25713 [==============================] - 149s - loss: 0.8540   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e39f919e8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of computational learning.\n",
      "\n",
      "\n",
      "== reinforcement learning ===\n",
      "\n",
      "result, on lavious data mining (kdd) the knowledge haster and machine learning is employed, noins are never program iasteen saused on novel systems work instance in recommendation systems.\n",
      "\n",
      "\n",
      "=== by researchers from machine learning is concerned with hin the nto hierd\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25713/25713 [==============================] - 149s - loss: 0.7120   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e2ae88518>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of computination structure in predictions in reconmectionist common. the data. if the tasks in the discovery of the conference on e9amples include the firite discovery of previously) unsupervised learning: elalurted that vias been used trins the ability theory of ai propermen is usifuration and regression. r is the maps input\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25713/25713 [==============================] - 149s - loss: 0.6189   \n",
      "Epoch 2/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.5548   \n",
      "Epoch 3/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.5110   \n",
      "Epoch 4/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.4772   \n",
      "Epoch 5/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.4530   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e39faa358>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of computer science known as computer vision.\n",
      "machine learning methods and they changed it rad sometimes used in recommendation systems.\n",
      "\n",
      "\n",
      "=== sparse dictionary learning has also been applied in several contexts. in classification, inputs are models of havistics and probability theory. it also benefited from at&t labs-researc\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25713/25713 [==============================] - 149s - loss: 0.4322   \n",
      "Epoch 2/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.4173   \n",
      "Epoch 3/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.4040   \n",
      "Epoch 4/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.3932   \n",
      "Epoch 5/5\n",
      "25713/25713 [==============================] - 149s - loss: 0.3828   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e39f91908>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning is the subfield of computer science around the same time. this line, too, was continued outside the ai/cs field, as \"connectionism\", by researchers from other disciplines including hopfield, rumelhart and hinton. their main success came in the mid-1980s with the reinvention of backpropagation.\n",
      "machine learning is a general term for any makhe\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 25754\n"
     ]
    }
   ],
   "source": [
    "path = 'sample.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 59\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# tf.get_default_session().close()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "input = tf.placeholder(tf.int32, [None, seq_len]) # batch, seq_len\n",
    "input_length = tf.placeholder(tf.int32, [None])\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, 20], -1.0, 1.0))\n",
    "emb = tf.nn.embedding_lookup(embeddings, input)\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(512)\n",
    "zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "c_state = tf.placeholder_with_default(zero_state.c, zero_state.c.shape)\n",
    "h_state = tf.placeholder_with_default(zero_state.h, zero_state.h.shape)\n",
    "initial_state = tf.nn.rnn_cell.LSTMStateTuple(c_state, h_state)\n",
    "#hidden_state_in = tf.placeholder(tf.float32, cell.zero_state(batch_size, tf.float32))\n",
    "out, hidden_state_out = tf.nn.dynamic_rnn(cell, emb, \n",
    "                                          sequence_length=input_length,\n",
    "                                          initial_state=initial_state, \n",
    "                                          dtype=tf.float32)\n",
    "pred = tf.layers.dense(out[:,-1,:], vocab_size, activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01634932  0.01809452  0.01748936 ...,  0.0180765   0.0173368\n",
      "   0.01481135]\n",
      " [ 0.01634932  0.01809452  0.01748936 ...,  0.0180765   0.0173368\n",
      "   0.01481135]\n",
      " [ 0.01634932  0.01809452  0.01748936 ...,  0.0180765   0.0173368\n",
      "   0.01481135]\n",
      " ..., \n",
      " [ 0.01634932  0.01809452  0.01748936 ...,  0.0180765   0.0173368\n",
      "   0.01481135]\n",
      " [ 0.01634932  0.01809452  0.01748936 ...,  0.0180765   0.0173368\n",
      "   0.01481135]\n",
      " [ 0.01634932  0.01809452  0.01748936 ...,  0.0180765   0.0173368\n",
      "   0.01481135]]\n",
      "LSTMStateTuple(c=array([[-0.1324746 , -0.11165032,  0.00908957, ..., -0.22269306,\n",
      "         0.25672165, -0.05743882],\n",
      "       [-0.1324746 , -0.11165032,  0.00908957, ..., -0.22269306,\n",
      "         0.25672165, -0.05743882],\n",
      "       [-0.1324746 , -0.11165032,  0.00908957, ..., -0.22269306,\n",
      "         0.25672165, -0.05743882],\n",
      "       ..., \n",
      "       [-0.1324746 , -0.11165032,  0.00908957, ..., -0.22269306,\n",
      "         0.25672165, -0.05743882],\n",
      "       [-0.1324746 , -0.11165032,  0.00908957, ..., -0.22269306,\n",
      "         0.25672165, -0.05743882],\n",
      "       [-0.1324746 , -0.11165032,  0.00908957, ..., -0.22269306,\n",
      "         0.25672165, -0.05743882]], dtype=float32), h=array([[-0.06170047, -0.05701941,  0.00460678, ..., -0.09753741,\n",
      "         0.11494599, -0.0300333 ],\n",
      "       [-0.06170047, -0.05701941,  0.00460678, ..., -0.09753741,\n",
      "         0.11494599, -0.0300333 ],\n",
      "       [-0.06170047, -0.05701941,  0.00460678, ..., -0.09753741,\n",
      "         0.11494599, -0.0300333 ],\n",
      "       ..., \n",
      "       [-0.06170047, -0.05701941,  0.00460678, ..., -0.09753741,\n",
      "         0.11494599, -0.0300333 ],\n",
      "       [-0.06170047, -0.05701941,  0.00460678, ..., -0.09753741,\n",
      "         0.11494599, -0.0300333 ],\n",
      "       [-0.06170047, -0.05701941,  0.00460678, ..., -0.09753741,\n",
      "         0.11494599, -0.0300333 ]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "pred_val, state = sess.run([pred, hidden_state_out], feed_dict={input: np.zeros((32,10)), \n",
    "                          input_length:[10]*32})\n",
    "print(pred_val)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.016511    0.01789943  0.01773306 ...,  0.0179087   0.01706824\n",
      "   0.01472727]\n",
      " [ 0.016511    0.01789943  0.01773306 ...,  0.0179087   0.01706824\n",
      "   0.01472727]\n",
      " [ 0.016511    0.01789943  0.01773306 ...,  0.0179087   0.01706824\n",
      "   0.01472727]\n",
      " ..., \n",
      " [ 0.016511    0.01789943  0.01773306 ...,  0.0179087   0.01706824\n",
      "   0.01472727]\n",
      " [ 0.016511    0.01789943  0.01773306 ...,  0.0179087   0.01706824\n",
      "   0.01472727]\n",
      " [ 0.016511    0.01789943  0.01773306 ...,  0.0179087   0.01706824\n",
      "   0.01472727]]\n",
      "LSTMStateTuple(c=array([[-0.1316891 , -0.08480705, -0.00442035, ..., -0.25247234,\n",
      "         0.31502163, -0.04883748],\n",
      "       [-0.1316891 , -0.08480705, -0.00442035, ..., -0.25247234,\n",
      "         0.31502163, -0.04883748],\n",
      "       [-0.1316891 , -0.08480705, -0.00442035, ..., -0.25247234,\n",
      "         0.31502163, -0.04883748],\n",
      "       ..., \n",
      "       [-0.1316891 , -0.08480705, -0.00442035, ..., -0.25247234,\n",
      "         0.31502163, -0.04883748],\n",
      "       [-0.1316891 , -0.08480705, -0.00442035, ..., -0.25247234,\n",
      "         0.31502163, -0.04883748],\n",
      "       [-0.1316891 , -0.08480705, -0.00442035, ..., -0.25247234,\n",
      "         0.31502163, -0.04883748]], dtype=float32), h=array([[-0.06117481, -0.04342559, -0.00223533, ..., -0.11036036,\n",
      "         0.13989122, -0.02566611],\n",
      "       [-0.06117481, -0.04342559, -0.00223533, ..., -0.11036036,\n",
      "         0.13989122, -0.02566611],\n",
      "       [-0.06117481, -0.04342559, -0.00223533, ..., -0.11036036,\n",
      "         0.13989122, -0.02566611],\n",
      "       ..., \n",
      "       [-0.06117481, -0.04342559, -0.00223533, ..., -0.11036036,\n",
      "         0.13989122, -0.02566611],\n",
      "       [-0.06117481, -0.04342559, -0.00223533, ..., -0.11036036,\n",
      "         0.13989122, -0.02566611],\n",
      "       [-0.06117481, -0.04342559, -0.00223533, ..., -0.11036036,\n",
      "         0.13989122, -0.02566611]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "pred_val, state = sess.run([pred, hidden_state_out], feed_dict={input: np.zeros((32,10)), \n",
    "                          c_state: state.c, \n",
    "                          h_state: state.h, \n",
    "                          input_length:[10]*32})\n",
    "print(pred_val)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, [None])\n",
    "y_onehot = tf.one_hot(y, vocab_size)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_onehot))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, array([[ 0.03777255,  0.01972683,  0.01629582, ...,  0.01999693,\n",
       "          0.01827611,  0.01763926],\n",
       "        [ 0.03777255,  0.01972683,  0.01629582, ...,  0.01999693,\n",
       "          0.01827611,  0.01763926],\n",
       "        [ 0.03777255,  0.01972683,  0.01629582, ...,  0.01999693,\n",
       "          0.01827611,  0.01763926],\n",
       "        ..., \n",
       "        [ 0.03777255,  0.01972683,  0.01629582, ...,  0.01999693,\n",
       "          0.01827611,  0.01763926],\n",
       "        [ 0.03777255,  0.01972683,  0.01629582, ...,  0.01999693,\n",
       "          0.01827611,  0.01763926],\n",
       "        [ 0.03777255,  0.01972683,  0.01629582, ...,  0.01999693,\n",
       "          0.01827611,  0.01763926]], dtype=float32)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run([optimizer, pred], feed_dict={input: np.zeros((32,10)), input_length:[10]*32, y_onehot: np.array([[1] + [0] * (vocab_size-1)] * 32)})\n",
    "sess.run([optimizer, pred], feed_dict={input: np.zeros((32,10)), input_length:[10]*32, y: np.ones(32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "in_seq = [text[i:i+seq_len] for i in range(len(text) - seq_len)]\n",
    "out_char = [text[i+seq_len] for i in range(len(text) - seq_len)]\n",
    "in_seq = [[char_indices[c] for c in seq] for seq in in_seq]\n",
    "out_char = [char_indices[c] for c in out_char]\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, array([[  4.24489832e-10,   9.99983191e-01,   1.95274996e-09, ...,\n",
      "          4.90937901e-10,   5.79409243e-10,   1.28684441e-09],\n",
      "       [  4.50844168e-10,   9.99982834e-01,   2.08199613e-09, ...,\n",
      "          5.35829936e-10,   5.97331851e-10,   1.35771683e-09],\n",
      "       [  1.13531951e-09,   9.99965549e-01,   5.29884625e-09, ...,\n",
      "          1.38945266e-09,   1.54315849e-09,   3.43986661e-09],\n",
      "       ..., \n",
      "       [  4.01151695e-10,   9.99983907e-01,   1.80596882e-09, ...,\n",
      "          4.63269173e-10,   5.22872246e-10,   1.21329591e-09],\n",
      "       [  5.02808462e-10,   9.99981403e-01,   2.29125852e-09, ...,\n",
      "          5.80067272e-10,   6.82739643e-10,   1.55292090e-09],\n",
      "       [  4.17971824e-10,   9.99983549e-01,   1.95269845e-09, ...,\n",
      "          5.05823161e-10,   5.57976276e-10,   1.28732114e-09]], dtype=float32), 3.9187477]\n"
     ]
    }
   ],
   "source": [
    "i += batch_size;\n",
    "if (i + batch_size < len(text)):\n",
    "    print(sess.run([optimizer, pred, cost], feed_dict={input: in_seq[i:i+batch_size], input_length:[10]*32, y: out_char[i:i+batch_size]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"machine learning is the subfield of comp\"\n",
    "    for i in range(320):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-seq_len:]])[np.newaxis,:]\n",
    "        preds = sess.run(pred, feed_dict={input: x, input_length:[10]})\n",
    "        next_char = choice(chars, p=preds[0])\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
